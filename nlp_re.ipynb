{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "nlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhyuns/class2022Spring/blob/main/nlp_re.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltUO0sYwyGfU"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6xZ08xsgO7"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy a file from github\n",
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/crime_punishment.txt\"\n",
        "os.system(\"curl \" + url + \" > crime_punishment.txt\")\n",
        "\n",
        "# read a text file in the server\n",
        "file = open(\"crime_punishment.txt\")\n",
        "text = file.read().replace(\"\\n\", \" \")\n",
        "file.close()"
      ],
      "metadata": {
        "id": "btgs9Nt-2Yj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbHEyyNHntcZ"
      },
      "source": [
        "# or copy/pase text here\n",
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write out a text file\n",
        "file = open(\"tmp.txt\", \"w\")\n",
        "file.write(text)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "9saTcc9C4Cjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45jV2UYs1GEC"
      },
      "source": [
        "text.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFR-cRaahTPy"
      },
      "source": [
        "' '.join(text.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq_lPZMHntcb"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC1fe7nWF6wN"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc42Plwx56YS"
      },
      "source": [
        "### Normalization  \n",
        "**Stemming** 어간 추출 대충의 패턴 규칙으로 어미를 잘라내는 것 (사전에 없는 어간 나올 수 있음)\n",
        "\n",
        "**Lemmatization** 표제어(기본 사전형) 추출.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFfoAr259Fs"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkbgNiPd8BdL"
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIIh5pYd8f74"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPgIzrjm8_1N"
      },
      "source": [
        "### Stopword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdM2FaN8ntcc"
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "nltk.download('stopwords')\n",
        "print(words)\n",
        "words = [w for w in words if not w in stopwords.words('english')]\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmwXTL0UA5aw"
      },
      "source": [
        "### Collocation, Concordance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fll4ygxNA3OJ"
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "text = nltk.corpus.gutenberg.raw('austen-emma.txt')\n",
        "words = retokenize.tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqVXlhIrAtmf"
      },
      "source": [
        "nltk.Text(words).collocations()  # default: (num=20, window_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq0wiutwA_au"
      },
      "source": [
        "nltk.Text(words).concordance('Emma', 79, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIAIhXvP_BjU"
      },
      "source": [
        "nltk.Text(words).dispersion_plot([\"Emma\", \"Knightley\", \"Frank\", \"Jane\", \"Harriet\", \"Robert\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWYZOFxq_ex2"
      },
      "source": [
        "# Distributional similarity: \n",
        "# find other words which appear in the same contexts as the specified word; \n",
        "# list most similar words first.\n",
        "nltk.Text(words).similar(\"Emma\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZihiVSBK_vy7"
      },
      "source": [
        "# Find contexts where the specified words appear; list most frequent common contexts first.\n",
        "nltk.Text(words).common_contexts([\"Emma\", \"she\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8TrCE14vGcT"
      },
      "source": [
        "### Frequency distribution, Frequency plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdY3m6zSBHic"
      },
      "source": [
        "fd = nltk.FreqDist(words).most_common(20)\n",
        "fd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tpZThNV-ftv"
      },
      "source": [
        "nltk.Text(words).plot(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSOSzIovvKvE"
      },
      "source": [
        "### Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIcAOAvqntce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4f7b49-0a89-4728-8d1e-28afcf6a04b7"
      },
      "source": [
        "nltk.download('words')\n",
        "nltk.corpus.words.words('en')[-20:-1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zymosis',\n",
              " 'zymosterol',\n",
              " 'zymosthenic',\n",
              " 'zymotechnic',\n",
              " 'zymotechnical',\n",
              " 'zymotechnics',\n",
              " 'zymotechny',\n",
              " 'zymotic',\n",
              " 'zymotically',\n",
              " 'zymotize',\n",
              " 'zymotoxic',\n",
              " 'zymurgy',\n",
              " 'Zyrenian',\n",
              " 'Zyrian',\n",
              " 'Zyryan',\n",
              " 'zythem',\n",
              " 'Zythia',\n",
              " 'zythum',\n",
              " 'Zyzomys']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAy_Ju7ntce"
      },
      "source": [
        "len(nltk.corpus.words.words('en'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIIqwosCRZa"
      },
      "source": [
        "### Extract information (pos tag, named entity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **POS tag list**:\n",
        "\n",
        "CC\tcoordinating conjunction \\\n",
        "CD\tcardinal digit \\\n",
        "DT\tdeterminer \\\n",
        "EX\texistential there (like: \"there is\" ... think of it like \"there exists\") \\\n",
        "FW\tforeign word \\\n",
        "IN\tpreposition/subordinating conjunction \\\n",
        "JJ\tadjective\t'big' \\\n",
        "JJR\tadjective, comparative\t'bigger' \\\n",
        "JJS\tadjective, superlative\t'biggest' \\\n",
        "LS\tlist marker\t1) \\\n",
        "MD\tmodal\tcould, will \\\n",
        "NN\tnoun, singular 'desk' \\\n",
        "NNS\tnoun plural\t'desks' \\\n",
        "NNP\tproper noun, singular\t'Harrison' \\\n",
        "NNPS\tproper noun, plural\t'Americans' \\\n",
        "PDT\tpredeterminer\t'all the kids' \\\n",
        "POS\tpossessive ending\tparent's \\\n",
        "PRP\tpersonal pronoun\tI, he, she \\\n",
        "PRP\\$\tpossessive pronoun\tmy, his, hers \\\n",
        "RB\tadverb\tvery, silently, \\\n",
        "RBR\tadverb, comparative\tbetter \\\n",
        "RBS\tadverb, superlative\tbest \\\n",
        "RP\tparticle\tgive up \\\n",
        "TO\tto\tgo 'to' the store. \\\n",
        "UH\tinterjection\terrrrrrrrm \\\n",
        "VB\tverb, base form\ttake \\\n",
        "VBD\tverb, past tense\ttook \\\n",
        "VBG\tverb, gerund/present participle\ttaking \\\n",
        "VBN\tverb, past participle\ttaken \\\n",
        "VBP\tverb, sing. present, non-3d\ttake \\\n",
        "VBZ\tverb, 3rd person sing. present\ttakes \\\n",
        "WDT\twh-determiner\twhich \\\n",
        "WP\twh-pronoun\twho, what \\\n",
        "WP\\$\tpossessive wh-pronoun\twhose \\\n",
        "WRB\twh-abverb\twhere, when \\"
      ],
      "metadata": {
        "id": "NLz0kp4kekaZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VBiObftCVwH"
      },
      "source": [
        "sent = \"I am Jhon from America and would like to go to Starbuck\"\n",
        "words = nltk.word_tokenize(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwKdu36WCewv"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos = nltk.pos_tag(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnjGT1HpClE0"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "NE = nltk.ne_chunk(pos)\n",
        "# common Entity types: ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, and GPE (geo-political entity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9DEIZ4lXQF"
      },
      "source": [
        "### Wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jypxOnw9hoyZ"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
        "\n",
        "wc = WordCloud().generate(text) \n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6xv5ClAl5xk"
      },
      "source": [
        "stopwords = set(STOPWORDS) \n",
        "stopwords.add('unto')\n",
        "wc = WordCloud(stopwords = stopwords).generate(text) \n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrVGVc0X9j7r"
      },
      "source": [
        "### Regular expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQKgoQFI_cG-"
      },
      "source": [
        "import re #필요한 package 불러오기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "re.search('a', 'abcdefa') #해당 string에서 a를 찾아라"
      ],
      "metadata": {
        "id": "qM5Uv5IyLeLG",
        "outputId": "9599174c-6770-4737-97b5-641044664493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='a'>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('a', 'abcdefa') #findall: 텍스트 안에 있는 모든 a를 찾아주는 것"
      ],
      "metadata": {
        "id": "KSVsBeO7LyOK",
        "outputId": "2a176004-2ddd-41e0-c001-ed84af376774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'a']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.sub('a', 'b', 'abcdefa') #sub: 모든 a를 b로 바꾸는 것"
      ],
      "metadata": {
        "id": "BSCfOsKuLzGi",
        "outputId": "5a856daa-7303-4e88-e8cd-7d3169458903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bbcdefb'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U2pS-NL9p38"
      },
      "source": [
        "'''       Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
        "\n",
        ".\t        Wildcard, matches any character\n",
        "^abc\t    Matches some pattern abc at the start of a string\n",
        "abc$\t    Matches some pattern abc at the end of a string\n",
        "[abc]\t    Matches one of a set of characters\n",
        "[^abc]    Matches anything but a set of characters\n",
        "[A-Z0-9]\tMatches one of a range of characters\n",
        "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
        "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
        "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
        "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
        "{n}\t      Exactly n repeats where n is a non-negative integer\n",
        "{n,}\t    At least n repeats\n",
        "{,n}\t    No more than n repeats\n",
        "{m,n}\t    At least m and no more than n repeats\n",
        "a(b|c)+\t  Parentheses that indicate the scope of the operators\n",
        "(...)     Matches whatever regular expression is inside the parentheses\n",
        "\\d\n",
        "Matches any decimal digit; this is equivalent to the class [0-9].\n",
        "\\D\n",
        "Matches any non-digit character; this is equivalent to the class [^0-9].\n",
        "\\s\n",
        "Matches any whitespace character; this is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
        "\\S\n",
        "Matches any non-whitespace character; this is equivalent to the class [^ \\t\\n\\r\\f\\v].\n",
        "\\w\n",
        "Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].\n",
        "\\W\n",
        "Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')\n",
        "engdict = nltk.corpus.words.words('en')"
      ],
      "metadata": {
        "id": "6kiN-P9f3UTE",
        "outputId": "350480c4-89a1-4280-8232-e9dbfce73f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "engdict"
      ],
      "metadata": {
        "id": "RzpyyoS03csT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(engdict)"
      ],
      "metadata": {
        "id": "HKJjbwgR3gSw",
        "outputId": "0fa3d37d-29e5-47bf-9179-ce0aa1ff96df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(engdict)"
      ],
      "metadata": {
        "id": "V1EkuTX43lCj",
        "outputId": "bddb9683-948d-4297-9c81-7c402d52eda2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235886"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.search('ed$', 'educated') # search는 해당되는 게 있기만 하면 찾아주는 것"
      ],
      "metadata": {
        "id": "KQCZ0_MJ5A4f",
        "outputId": "2d39d3d0-59a1-42e2-93ee-795ca21402a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(6, 8), match='ed'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp3_Dm9Q_tNQ"
      },
      "source": [
        "result = [w for w in engdict if re.search('ed$', w)]\n",
        "# engdict라는 list가 있는데 engdict에 있는 각각의 아이템을 하나씩 w로 받음\n",
        "# 이후 re.search에 들어가는 것, 'ed$'는 regular expression에 있는 규칙\n",
        "# ed$에서 $ 표시는 string의 끝에서 ed가 발견되면, ^는 string의 맨 앞에서 발견되면 이라는 뜻\n",
        "# 위의 코드는 w라는 string 안에서 ed로 끝나는 단어가 있다면 w에 ed로 끝나는 단어들만 모이는 것\n",
        "# ed로 끝나는 단어가 없다면 if는 그냥 지나치는 코드가 되는 것임\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(result)"
      ],
      "metadata": {
        "id": "_jyd0W-66EIL",
        "outputId": "cdb34a1c-cee3-4835-e585-dfa5a4f2c542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9192"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [w for w in engdict if re.search('^..j..t..$', w)]\n",
        "# .은 아무 character(알파벳)든 상관 없다는 뜻\n",
        "# 위의 것을 해석하면 세번째에 j, 여섯번째에 t가 나오고 뒤에 두 알파벳이 더 나오는 단어를 찾으라는 것임\n",
        "result"
      ],
      "metadata": {
        "id": "_GW2F5vE5zFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = [w for w in engdict if re.search('^[ghi][mno][jlk][def]$', w)]\n",
        "# 대괄호는 대괄호 안에 있는 character 중에 하나랑만 겹치면 된다는 뜻\n",
        "# 위의 코드는 4개의 character로 되어 있는데 첫 번째 character은 ghi중에 하나 두 번째 character는 mno중에 하나 이런식으로 해석하면 됨\n",
        "result"
      ],
      "metadata": {
        "id": "I1j2xlNk51j5",
        "outputId": "82c335b6-1dfb-4292-d7a1-403dfd061778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gold', 'golf', 'hold', 'hole']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [w for w in engdict if re.search('^[ah]+$', w)]\n",
        "# +는 해당 character가 한 번 이상 나오는 것을 찾는 것\n",
        "# 시작부터 끝까지 a또는 h만 한 번 이상 나오는 것을 찾아라 라고 해석하면 됨\n",
        "print(result[:10])"
      ],
      "metadata": {
        "id": "oVWiwhk454Nc",
        "outputId": "d6441538-c629-4ab9-9c72-66d9704133d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'aa', 'ah', 'aha', 'h', 'ha', 'hah']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "wsj = nltk.corpus.treebank.words()\n",
        "wsj # type은 list"
      ],
      "metadata": {
        "id": "SGKCZnBA75Kg",
        "outputId": "d8b67978-fee9-439e-ec36-11cd450f57d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1a5mQYj4hwn"
      },
      "source": [
        "result = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
        " # 시작 부분에 대한 조건은 없음, 괄호가 되어 있고 중간에 바가 있음\n",
        " # ed 혹은 ing로 끝나는 단어를 찾아라\n",
        "\n",
        "# result = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
        " # 0-9: 숫자라는 뜻, 숫자가 한 개 이상 나오고 .이 나오고 또 숫자가 하나 이상 나오는 것을 찾아라\n",
        " # .은 .이 아니라 .\\(거꾸로 된 slash)라고 써야 됨\n",
        "\n",
        "# result = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
        " # $도 실제 $를 search하고 싶으면 \\$라고 써야 됨\n",
        " # 어떤 대문자 알파벳이 한 개이상 나오고 $가 나오는 것을 찾아라\n",
        "\n",
        "# result = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
        " # {}는 중괄호 앞에 있는 것이 몇 번 나오는지에 대한 조건을 설정함\n",
        " # 숫자가 네 번 나오는 것을 찾아라\n",
        "\n",
        "# result = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
        " # 숫자가 한 번 이상 나오고 dash가 나오고 소문자 알파벳이 3개에서 5개 사이로 나오는 것을 찾아라\n",
        " \n",
        "# result = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
        " # 소문자 알파벳이 5개 이상 나오고 dash 나오고 소문자가 2개에서 3개 사이가 나오고 dash가 나오고 소문자가 6개 이하인 것을 찾아라\n",
        "\n",
        "result = sorted(set(result)) # 이 코드가 없으면 알파벳 순이 아니라 그냥 찾는 순서 대로 나옴\n",
        "print(result[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/my/main/friends_season01_script.txt\"\n",
        "os.system(\"curl \" + url + \" > friends_season01_script.txt\")\n",
        "# url로 text 가져오기\n",
        "\n",
        "# read a text file in the server, 변수로 불러오기\n",
        "file = open(\"friends_season01_script.txt\") # 불러오기\n",
        "text = file.read()\n",
        "file.close() # 불러오고 닫기\n",
        "text"
      ],
      "metadata": {
        "id": "05zHW52eKatf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(text)"
      ],
      "metadata": {
        "id": "0PAUE0NsAA1h",
        "outputId": "a4740534-7617-473c-aa94-18c022b7c30d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "id": "6k9e5nKOAGt0",
        "outputId": "5e415627-79a5-4d66-a76a-49474dd801c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "471160"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '(?<=: ).+(?=[\\.|\\?|\\!])'\n",
        "# search는 하나만 찾을 수 있지만 findall은 특정 패턴에 해당하는 것을 모든 것을 list화 해서 가져와 줌\n",
        "# (?<= 내가 찾기 원하는 것 앞에 나오는 것 적기, 앞의 환경).내가 찾으려는 것의 패턴 적기(?= 내가 찾기 원하는 것 뒤에 나오는 것 적기, 뒷 환경)\n",
        "# 이러면 저 점에 해당하는 character 하나를 찾아줌\n",
        "# :가 앞에 오고 .또는 ?또는 !로 끝나는 한 개 이상의 chracter를 찾아라\n",
        "# 문장들이 list화 되어서 나옴\n",
        "sent = re.findall(pattern, text)\n",
        "sent\n",
        "text = '\\n'.join(sent)\n",
        "# \\n은 enter, 위의 코드를 실행하면 엔터를 기준으로 모든 문장이 길게 하나로 합쳐짐, 원 상태로 돌아가는 것"
      ],
      "metadata": {
        "id": "8yOBHr-7Qw2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write out a text file\n",
        "file = open(\"tmp.txt\", \"w\") #(\"저장될 파일 이름(자신이 원하는 이름 쓰기)\", \"w\")\n",
        "file.write(text)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "CHZwCWeTUPgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "과제: 프렌즈 대본에 나오는 모든 Rachel을 자신의 학번으로 바꿔서 text로 다시 저장하기\n",
        "\n",
        "20220509.ipynb 파일 하나, 20220509.txt 파일 하나 두 개의 파일이 나와야 함\n",
        "\n",
        "5월 11일 수업시간 전까지 제출"
      ],
      "metadata": {
        "id": "tIkSmcDlCwOC"
      }
    }
  ]
}